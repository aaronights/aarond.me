(window.webpackJsonp=window.webpackJsonp||[]).push([[28],{254:function(e){e.exports={data:{post:{title:"To the fourth power: The Next Generation",content:'<p>As the next generation of hardware approaches, the estimates of what the hardware will consist of are starting to brew.</p>\n<p>Deep consideration and my super expertise have lead to a groundbreaking formula: The Next Generation of hardware will have key aspects increased by a factor of four.</p>\n<p><strong>The bus speeds</strong> - In this sense the bus refers to the throughput data transfer rates of the components inside the system. Both consoles use standard SATA technology for their optical and hard drives. However, both use revision 1.0 of the SATA standard, limiting the maximum data throughput level to 1.5 Gbit/s. Revision 3.0 of the SATA standard was made available in 2009 and increases the throughput level by four times to 6 Gbit/s. There will also be other speed increases, with the data transfer rates between the CPU, GPU and memory also needing to be increased to accommodate new graphical technologies.</p>\n<p><strong>The optical drive</strong> – this one is a bit less general than the other points. The Playstation 3 boasts having Blu-ray discs with their enormous size as its storage media. However, due to the Playstation 3 launching while this technology was still in its infancy it is crippled by its low speed. The 2x drive in the Playstation 3 is the slowest available – anything slower would not be able to play standard Blu-ray movie discs correctly. Most common Blu-ray drives now operate at speeds four times faster than the one present in the Playstation 3, with even faster ones becoming prominent. Having a faster storage medium would not only reduce loading times but allow for more aspects of a game to be streamed directly from the disc without the need for large amounts of caching in memory or even installing to a hard drive. On the Xbox 360 the matter is simply increasing the data storage size. Going from the current 7.5GB to a minimum of 30GB is an obvious requirement for the next generation.</p>\n<p><strong>The memory</strong> – Most people know that the best and cheapest way to boost the performance in a computer is to add more memory. Right now the biggest complaint with developers on the current generation consoles is the lack of memory. As developers become more familiar with the hardware in a system they are able to get more performance out of a given processor. However, the amount of memory in a system remains constant. High resolution textures, models and other assets that can be implemented are forced to be compressed and have their quality and detail reduced in other to allow them to fit into the memory on a system. Both the Playstation 3 and Xbox 360 have 512MB of memory. To accommodate for future expansion, a minimum of 2GB should be expected in next generation hardware.</p>\n<p><strong>The hard drive (speed)</strong> – Both consoles currently ship with hard drives that are among the slowest available on the market. The decision to use low speed 2.5” laptop hard drives was most likely done to keep the overall size of the systems down. Using a faster hard drive wouldn’t just increase performance with games running directly from it but would also allow for more effective paging – using a small area of the hard drive for another level of cache. Even if the consoles shipped with an extremely fast optical drive, paging on the hard drive would allow for the system to use both drives in tandem, dramatically increasing performance. It is also possible that consoles could move from magnetic hard drives to much faster flash chips. However, with the digital revolution apparently arriving soon the higher storage levels a hard drive offers might keep them around.</p>\n<p><strong><em>A few more points:</em></strong></p>\n<p>The next generation of systems will make heavy use of virtualisation. The Xbox 360 currently has a strong hypervisor governing over all executed titles. In doing this a game does not get complete control of the console when it runs. Rather, the hypervisor provides it with a controlled environment to operate. Doing this allows system level processes, including things like background downloads, custom soundtracks and notifications, to remain active while in a game. It also has the biggest advantage of making a system more secure. By making games run within this controlled environment, an exploit in a game is very difficult to be used to obtain complete control of a system. It is designed in such a way that the governing hypervisor is the only thing capable of executing entirely new processes, meaning that if a game wants to execute something it must make a request to the hypervisor to do it rather than doing it directly. While this can lower performance the enhanced level of security can dramatically help cut down on something that every publisher fears – exploits that allow for piracy. The Playstation 3 does something similar. Sony used its new Cell architecture for the PS3. Cell uses a central processing core supplemented by seven smaller cores. The operating system of the Playstation 3 locks one of these supplementary cores for its exclusive use. However, most likely due to a rushed development cycle for the console, many things that games do bypass the operating system completely and ‘hook’ directly into the systems hardware, working outside of the controlled environment. This also leads to a disadvantage for Sony when it moves into the next generation. I believe that the next Xbox will have 99% backwards compatibility with past games. Its use of virtualised environments allows for easy transfer of titles. Rather than adapting individual titles to the platform, the next Xbox would just have to adapt the virtual environment that the Xbox 360 used to its hardware. This would be possible even if the system changed its processor architecture to the rumoured ARM-based system. The Playstation 3 would be much more of a challenge. Its use of the highly complex Cell architecture combined with a standard and separate graphics processor and the flaws in its method of virtualisation would make backwards compatibility a far more daunting proposition for Sony. It also doesn’t help that development of the Cell has stopped by all other companies that were originally backing it, making it close to an abandoned piece of technology.</p>\n<h1 id="the-next-generation-will-use-a-more-enhanced-and-powerful-version-of-a-hypervisor-controlled-virtualised-environment-for-games-to-operate-on"><a href="#the-next-generation-will-use-a-more-enhanced-and-powerful-version-of-a-hypervisor-controlled-virtualised-environment-for-games-to-operate-on" aria-hidden="true"><span class="icon icon-link"></span></a> "The next generation will use a more enhanced and powerful version of a hypervisor controlled virtualised environment for games to operate on..."</h1>\n<p>There are a few more points too: virtualisation could allow for code portability across a range of processors. Different iterations of the console could change processor and still retain full compatibility. The use of low powered chips like ARM could also lead to a size revolution: Using Flash Memory and low power usage processor architectures could allow an entire next generation platform to be a single system of a chip with no moving parts or even wiring. Besides an optical drive, an entire console could fit in your hand.</p>\n',date:"2012-06-17T00:00:00.000Z",timeToRead:12}}}}}]);